## pgbench tutorial
* pgbench is a simple program for running benchmark tests on PostgreSQL. It runs the **same sequence of SQL commands over and over**, possibly in multiple concurrent database sessions, and then calculates the average transaction rate (transactions per second). By default, pgbench tests a scenario that is loosely based on TPC-B, involving five SELECT, UPDATE, and INSERT commands per transaction. However, it is easy to test other cases by writing your own transaction script files.
* There are mainly two testing model:
	* one is to run a given number of transactions, and compute the total time consumed;
	* another is to run a given total time, and compute how many transactions finished, aka, -T option;
* The default TPC-B-like transaction test requires specific tables to be set up beforehand. pgbench should be invoked with the -i (initialize) option to create and populate these tables. (When you are testing a custom script, you don't need this step, but will instead need to do whatever setup your test needs.) The initilized database should contain four tables, pgbench_accounts(100000 * scale rows), pgbench_branches(1 * scale rows), pgbench_tellers(10 * scale rows), and pgbench_history which is used as workspace and initialized as empty;
* **fillfactor** is an option specified when creating tables. The fillfactor for a table is a percentage between 10 and 100. 100 (complete packing) is the default. When a smaller fillfactor is specified, INSERT operations pack table pages only to the indicated percentage; the remaining space on each page is reserved for updating rows on that page. This gives UPDATE a chance to place the updated copy of a row on the same page as the original, which is more efficient than placing it on a different page. For a table whose entries are never updated, complete packing is the best choice, but in heavily updated tables smaller fillfactors are appropriate.
* In nearly all cases, you'll need some options to make a useful test. The most important options are -c (number of clients), -t (number of transactions), -T (time limit), and -f (specify a custom script file). 
* pgbench has support for running custom benchmark scenarios by replacing the default transaction script (described above) with a transaction script read from a file (-f option). In this case a "transaction" counts as one execution of a script file. You can even specify multiple scripts (multiple -f options), in which case a random one of the scripts is chosen each time a client session starts a new transaction.
* Good practices:
	* It is very easy to use pgbench to produce completely meaningless numbers. Here are some guidelines to help you get useful results.
	* In the first place, never believe any test that runs for only a few seconds. Use the -t or -T option to *make the run last at least a few minutes*, so as to average out noise. In some cases you could need hours to get numbers that are reproducible. It's a good idea to try the test run a few times, to find out if your numbers are reproducible or not.
	* For the default TPC-B-like test scenario, *the initialization scale factor (-s) should be at least as large as the largest number of clients you intend to test (-c)*; else you'll mostly be measuring update contention. There are only -s rows in the pgbench_branches table, and every transaction wants to update one of them, so -c values in excess of -s will undoubtedly result in lots of transactions blocked waiting for other transactions.
	* The default test scenario is also quite sensitive to how long it's been since the tables were initialized: accumulation of dead rows and dead space in the tables changes the results. To understand the results you must keep track of the total number of updates and when vacuuming happens. If autovacuum is enabled it can result in unpredictable changes in measured performance.
	* A limitation of pgbench is that it can itself become the bottleneck when trying to test a large number of client sessions. This can be alleviated by running pgbench on a different machine from the database server, although low network latency will be essential. It might even be useful to run several pgbench instances concurrently, on several client machines, against the same database server.