---
layout: post
title:  "Greenplum发布5.11.0"
author: Jasper Li
date:   2018-09-14 22:00 +0800
published: false
---

# Pivotal Greenplum 5.11.0 发布

## Greenplum 5.11介绍

Pivotal的Greenplum是基于MPP架构的数据库产品，它可以满足下一代大数据仓库和大规模的分析任务的需求。通过自动对数据进行分区以及多节点并行执行查询等方式，它使一个包含上百节点的数据库集群运行起来就像单机版本的传统数据库一样简单可靠，同时提供了几十倍甚至上百倍的性能提升。除了传统的SQL，Greenplum还支持MapReduce，文本索引，存储过程等很多分析工具，所支持的数据量可以从上百GB到几百TB。
Greenplum 5.11.0可以从这里下载（https://network.pivotal.io/products/pivotal-gpdb），文档在这里（https://gpdb.docs.pivotal.io/），开源社区的主页在这里（http://greenplum.org/），源代码在github上（https://github.com/greenplum-db/gpdb）。5.11.0是小版本升级，包含了新功能及bug修复，具体介绍如下。

## 新增特性

### gpbackup/gprestore支持增量备份和恢复

Gpbackup/gprestore工具支持对AO表生成增量备份，并对其进行恢复。当为分区表时，只有变化的分区数据会被备份和恢复。一个完整的增量备份包括下面几个部分：

* 初始的全量备份
* 从初始全量备份开始的增量几个

对增量备份的数据进行恢复时，需要完整的初始数据和全部的增量备份数据。增量备份适用于对数据有少量更新的场景。

### gpbackup/gprestore支持新的插件

从5.11.0开始，gpbackup/gprestore正式支持了如下插件：

* DD Boost 存储插件：通过--plugin-config 参数可以指定将数据备份到Dell EMC Data Domain 存储方案上，或者从其上面恢复数据
* S3存储插件：通过--plugin-config 参数可以指定将数据备份到Amazon的S3存储方案上，或者从其上面恢复数据

` --plugin-config`参数不再依赖--single-data-file 或者 --metadata-only参数

### GPORCA提升嵌套（nested） join性能

GPORCA提升了嵌套join的性能，GPORCA生成的查询计划可以允许物化内循环数据时，与其它操作并行执行。老的查询计划无法使其与其它操作并行执行

###GPORCA支持GiST索引

GPORCA在生成查询计划时可以使用GiST索引。GiST索引支持对自定义数据类型和操作创建索引。例如Greenplum的PostGIS扩展可以用GiST对地理信息数据创建索引。

### 增强分区表的信息收集功能

在这个版本中，ANALYZE增加了一下对分区表的增强：

* ANALYZE可以对分区表的字表统计额外的信息，即HyperLogLog统计信息。当对多个子分区进行聚合操作时，相比于常规的统计信息，HyperLogLog统计可以对distinct数值的个数生成更精确的估计。HLL不可用时，ORCA会通过其他统计信息来估计distince数值的个数。
* 如果所有的其它子分区都有统计信息，对子分区执行ANALYZE操作时，会同时更新根分区的统计信息。当某一个子分区的数据发生变化时，对其执行ANALYZE操作会同时更新根分区的统计信息。GPORCA使用根分区的统计信息来生成查询计划。

### pg_hba.conf中支持主机名

pg_hba.conf用来控制Greenplum的客户端访问权限，在Greenplum 5.11中，可以在pg_hba.conf文件中使用客户端的主机名指定客户端地址。

在Greenplum 5.11.0中，gpinitsystem的配置文件gpinitsystem_config中增加了HBA-HOSTNAMES参数。它可以控制向pg_hba.conf增加访问配置信息时，是否使用主机名的形式。它的默认值是0，表示只允许使用IP地址的形式。HBA_HOSTNAMES=1时，使用主机名的形式更新pg_hba.conf。在5.11.0之前，只允许使用IP地址，或者IP端两种方式。

### Greenplu-Kafka连接器支持新功能

* gpkafka可以同时解析Key和Value字段
* 支持新的Kafka消息格式：bianry，分隔的文本，avro，json
* 增加了`--debug-port`参数，可以打印更多的调试信息
* 允许为gpkafka使用的表指定单独的schema
* 可以在加载时候对输入表和输出表的列进行转换处理
  * 当源数据结构与目标表结构相同时，可以省略Input表的column定义
  * 可以用`__IGNORE__ `来忽略输入表的列
  * 可以通过`MAPPING`指定输出时需要进行的变换

### PXF支持Kerberos

PXF支持Kerberos认证的HDFS上读取文本类型的数据

### 增加对Oracle Linux 7的支持

5.11支持使用Redhat兼容内核（RHCK）的Oracle Linux 7.4

## 改变的功能

### PXF的性能提升

在5.11之前，当使用用户模拟功能时，PXF会在请求结束时清空系统缓存。5.11中PXF会保留缓存空间并尝试重用这些数据，从而提高性能。

### 外部表支持了filter下推

外部表的filter条件下推现在默认打开了，目前只有PXF外部表支持filter下推。

### Greenplu-Kafka连接器的行为变化

* 调试信息默认不再往标准输出打印
* gpkafka使用的内部表命名规则发生变化
* gpkafka不再受限只能使用2个CPU核

### GPORCA支使用gp_enable_relsize_collection参数

当表没有统计信息时，GPORCA和Planer使用对表的函数使用默认的估计值，当gp_enable_relsize_collection为on时，会使用表的大小进行估计。这个操作会在高负载下改善查询优化的时间，降低资源的使用，但可能导致次优的查询计划。在5.11之前，只有Planner会使用这个参数

### gp_max_csv_line_length的最大值增大

在5.11.0中`gp_max_csv_line_length`允许的最大值为1G，在这之前它允许的最大值为4M。这个参数表示允许导入的最大CSV文件的行大小。

### SUBPARTITION行为的增强

当使用`CREATE TABLE`和`SUBPARTITION`创建多级分区表时，语法检查比之前更加严格。

### Madlib升级到1.15

Madlib 1.15包含了新的功能增强和bug修复，详细信息可以参考Malib的网站：http://madlib.apache.org/

## 试验特性

Pivotal Greenplum是基于开源的greenplum-db发布的，它包含了正在开发中的很多激动人心的功能，任何针对这些功能的反馈都会推进我们改进相关功能，并在将来的版本中正式支持。Greenplum 5.11.0中有如下实验功能：

* Recursive CTE（Common Table Expressin）定义了一个可以在同一个查询里重复使用的临时表，可以大大简化SQL语句。Greenplum 5.11.0中CTE定义支持了recursive关键字，从而允许在CTE定义时可以递归的引用自己。

* SUSE平台上基于Resource group的资源管理

  由于内核版本限制，SUSE11上的cgroup无法提供Resource group运行所依赖的功能，SUSE12解决了启用cgroup以后引起的Greenplum性能问题。

* 存储框架API：合作伙伴，用户和开源社区可以根据API 来支持自己的备份和恢复方案

* Pivotal Greenplum-Kafka连接器

  用户可以通过gpkafka，从Kafka中实时向Greenplum中加载流数据

## 移除的功能

5.11.0中数据库的gp_max_csv_line_length 参数被标记为废弃，在之后的版本中会被移除。

## 与开源版的比较

商业版的Greenpum除了包含了开源版本的全部功能，此外还有以下增强的功能：

* 打包安装及部署脚本
* 支持了QuickLZ压缩算法
* 图形界面的管理工具，Greenplum Commander Center
* 内置的监控工具，Workload Manager
* 基于SQL的文本检索引擎，GPText
* Spark Connector
* Gemfire Connector
* DataDirect的ODBC和JDBC驱动
* Pivotal Greenplum Informatica Connector
* Pivotal Greenplum Kafka Connector
* gpcopy备份迁移工具

Pivotal的Greenplum暂不支持如下的社区模块

* The PXF JDBC connector.
* The PXF Apache Ignite connector.



