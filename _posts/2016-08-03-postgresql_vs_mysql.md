## PostgreSQL vs MySQL
* MySQL uses rollback segment to achieve multiple-version tuple; so MySQL updates a tuple in place, but the tuple or the page need to be copied to the rollback segment; copying tuple to the rollback segment need WAL log, so I guess the rollback segment is on disk instead of memory;
* The cost of transaction abortion is huge in MySQL, since it has to copy the tuple in rollback segment back to the origin tuple page;
* PostgreSQL uses append-style-update to achive multiple-version tuple, in order to avoid huge index update cost, PG adopt an optimization called HOT, which means that if the new appended tuple is in the same page with the previous tuple, then this new tuple would not be reflected in the index tree, instead, the original tuple would point to the same page new tuple; a proper 'fillfactor' parameter of the table can help decrease the possibility of tuples in different page, thus improve the update efficiency;
* SSD is good for read, while it has the disadvantage called Write Amplification(see: http://blog.csdn.net/cywosp/article/details/29812433), unless SSD is writen in a sequential order;
* The tuples of MySQL are stored on the dist in B+ tree model, so there must be a primary key for tables in MySQL, if no, MySQL would add an additional PK column; and for secondary indies of MySQL, the key is the indexed column, the value is the primary key value, so for a look up using non-primary column, it would first traverse secondary index if possible, and then find the primary key of the tuple, then look up the tuple in the primary index; this extra index loop up cost is pretty huge when depth of primary index is large; also, the cost of inserting one tuple is larger than PG because it has to handle the split cases of B+ tree(though PG has split cases for B tree as well, but there may be no index for tables in PG);
* Using index scan, there is a problem of random IO for both PG and MySQL, PG adopts an optimization called bitmap scan to improve the IO efficiency, i.e, after traversing the index tree and getting the ctid of one tuple, it does not access the tuple immediately, instead, it sort the ctids of all the tuples queried from index tree, and make it like a sequential scan as much as possible; another optimization of random IO is CLUSTER tuples by index;
* For SSD, there are direct IO and buffer IO, PG implements shared buffer in buffer IO style, except for CHECKPOINT, which uses direct IO; if using buffer IO, OS would apply optimization to combine several IOs into a single real SSD IO, which can somehow ease the Write Amplification of SSD;
* For replication, there are two ways for PG: logical replication and physical replication; one disadvantage of logical replication is the significant delay for long transaction, because the replica can only apply the WAL log when the transaction on the master has committed; for situations where consistency between master and replica is strictly required, physical replication is recommended;
* read transaction on hot standby would block the WAL recovery on replica?